#!/usr/bin/env python
"""
Script to process queued backdated analysis jobs without requiring Celery broker
"""

import os
import sys
import django
from datetime import datetime, timedelta

# Setup Django environment
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'analytics.settings')
django.setup()

from core.models import FileProcessingJob, BackdatedAnalysisResult, DataFile
from core.tasks import run_backdated_analysis

def process_pending_backdated_jobs():
    """Process pending backdated analysis jobs"""
    print("ğŸ”§ Processing pending backdated analysis jobs...")
    print("=" * 50)
    
    # Get pending jobs with backdated analysis
    pending_jobs = FileProcessingJob.objects.filter(
        status='PENDING',
        requested_anomalies__contains=['backdated']
    ).order_by('created_at')
    
    print(f"ğŸ“‹ Found {pending_jobs.count()} pending backdated analysis jobs")
    
    if pending_jobs.count() == 0:
        print("â„¹ï¸  No pending backdated analysis jobs found")
        return
    
    processed_count = 0
    failed_count = 0
    
    for job in pending_jobs:
        print(f"\nğŸ”„ Processing job: {job.id}")
        print(f"   ğŸ“ File: {job.data_file.file_name if job.data_file else 'N/A'}")
        print(f"   ğŸ“… Created: {job.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # Update job status to processing
            job.status = 'PROCESSING'
            job.started_at = datetime.now()
            job.save()
            
            # Run backdated analysis directly
            print("   ğŸ” Running backdated analysis...")
            result = run_backdated_analysis(str(job.id))
            
            if result and result.get('status') == 'completed':
                print("   âœ… Backdated analysis completed successfully!")
                processed_count += 1
                
                # Check if results were saved
                backdated_analysis = BackdatedAnalysisResult.objects.filter(
                    data_file=job.data_file,
                    analysis_type='enhanced_backdated'
                ).first()
                
                if backdated_analysis:
                    print(f"   ğŸ“Š Results saved: {backdated_analysis.get_backdated_count()} entries found")
                    print(f"   ğŸ’° Total amount: {backdated_analysis.get_total_amount():,.2f}")
                else:
                    print("   âš ï¸  Results not found in database")
            else:
                print(f"   âŒ Backdated analysis failed: {result.get('error', 'Unknown error')}")
                failed_count += 1
                
        except Exception as e:
            print(f"   âŒ Error processing job: {e}")
            failed_count += 1
            
            # Update job status to failed
            job.status = 'FAILED'
            job.error_message = str(e)
            job.completed_at = datetime.now()
            job.save()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š Processing Summary:")
    print(f"   âœ… Successfully processed: {processed_count}")
    print(f"   âŒ Failed: {failed_count}")
    print(f"   ğŸ“‹ Total jobs: {pending_jobs.count()}")

def check_and_fix_failed_jobs():
    """Check and fix failed backdated analysis jobs"""
    print("\nğŸ”§ Checking failed backdated analysis jobs...")
    print("=" * 50)
    
    # Get failed jobs with backdated analysis
    failed_jobs = FileProcessingJob.objects.filter(
        status='FAILED',
        requested_anomalies__contains=['backdated']
    ).order_by('-created_at')
    
    print(f"ğŸ“‹ Found {failed_jobs.count()} failed backdated analysis jobs")
    
    if failed_jobs.count() == 0:
        print("â„¹ï¸  No failed backdated analysis jobs found")
        return
    
    for job in failed_jobs[:5]:  # Show last 5 failed jobs
        print(f"\nâŒ Failed Job: {job.id}")
        print(f"   ğŸ“ File: {job.data_file.file_name if job.data_file else 'N/A'}")
        print(f"   ğŸ“… Created: {job.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   âš ï¸  Error: {job.error_message}")
        
        # Check if backdated analysis exists despite failure
        backdated_analysis = BackdatedAnalysisResult.objects.filter(
            data_file=job.data_file,
            analysis_type='enhanced_backdated'
        ).first()
        
        if backdated_analysis:
            print(f"   âœ… Backdated analysis exists: {backdated_analysis.get_backdated_count()} entries")
        else:
            print(f"   âŒ No backdated analysis found")

def main():
    """Main function"""
    print("ğŸš€ Backdated Analysis Queue Processor")
    print("=" * 50)
    
    # Process pending jobs
    process_pending_backdated_jobs()
    
    # Check failed jobs
    check_and_fix_failed_jobs()
    
    print("\n" + "=" * 50)
    print("âœ… Queue processing completed!")
    print("ğŸ’¡ Run 'python monitor_backdated_queue.py' to check results")

if __name__ == "__main__":
    main() 